{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e426cd04-c053-43e8-b505-63cee7956a53",
   "metadata": {},
   "source": [
    "# Welcome to a very busy Week 8 folder\n",
    "\n",
    "## We have lots to do this week!\n",
    "\n",
    "We'll move at a faster pace than usual, particularly as you're becoming proficient LLM engineers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cf5389-93c5-4523-bc48-78fabb91d8f6",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Especially important this week: pull the latest</h2>\n",
    "            <span style=\"color:#900;\">I'm continually improving these labs, adding more examples and exercises.\n",
    "            At the start of each week, it's worth checking you have the latest code.<br/>\n",
    "            First do a <a href=\"https://chatgpt.com/share/6734e705-3270-8012-a074-421661af6ba9\">git pull and merge your changes as needed</a>. Any problems? Try asking ChatGPT to clarify how to merge - or contact me!<br/><br/>\n",
    "            After you've pulled the code, from the llm_engineering directory, in an Anaconda prompt (PC) or Terminal (Mac), run:<br/>\n",
    "            <code>conda env update --f environment.yml --prune</code><br/>\n",
    "            Or if you used virtualenv rather than Anaconda, then run this from your activated environment in a Powershell (PC) or Terminal (Mac):<br/>\n",
    "            <code>pip install -r requirements.txt</code>\n",
    "            <br/>Then restart the kernel (Kernel menu >> Restart Kernel and Clear Outputs Of All Cells) to pick up the changes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc0e1c1c-be6a-4395-bbbd-eeafc9330d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just one import to start with!!\n",
    "\n",
    "import modal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5c8533-9f66-448f-b9b2-133d1ff50639",
   "metadata": {},
   "source": [
    "# Setting up the modal tokens\n",
    "\n",
    "The first time you run this, please uncomment the next line and execute it.  \n",
    "This is the same as running `modal setup` from the command line. It connects with Modal and installs your tokens.\n",
    "\n",
    "A student on Windows mentioned that on Windows, you might also need to run this command from a command prompt afterwards:  \n",
    "`modal token new`  \n",
    "(Thank you Ed B. for that!)\n",
    "\n",
    "And I've also heard that in some situations, you might need to restart the Kernel of this jupyter notebook after running this. (Kernel menu >> Restart Kernel and Clear Outputs of All Cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d240622-8422-4c99-8464-c04d063e4cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The web browser should have opened for you to authenticate and get an API \n",
      "token.\n",
      "If it didn't, please copy this URL into your web browser manually:\n",
      "\n",
      "\n",
      "The web browser should have opened for you to authenticate and get an API \n",
      "token.\n",
      "If it didn't, please copy this URL into your web browser manually:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+- Error ---------------------------------------------------------------------+\n",
      "| 'charmap' codec can't encode character '\\u280b' in position 0: character    |\n",
      "| maps to <undefined>                                                         |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Remove the '# ' from the next line and run the cell\n",
    "!modal setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b133701-f550-44a1-a67f-eb7ccc4769a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hello import app, hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3f73ae-1295-49f3-9099-b8b41fc3429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.run():\n",
    "    reply=hello.local()\n",
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d8c6f9-edc7-4e52-9b3a-c07d7cff1ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.run():\n",
    "    reply=hello.remote()\n",
    "reply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e8d804-c027-45fb-8fef-06e7bba6295a",
   "metadata": {},
   "source": [
    "# Before we move on -\n",
    "\n",
    "## We need to set your HuggingFace Token as a secret in Modal\n",
    "\n",
    "1. Go to modal.com, sign in and go to your dashboard\n",
    "2. Click on Secrets in the nav bar\n",
    "3. Create new secret, click on Hugging Face, this new secret needs to be called **hf-secret** because that's how we refer to it in the code\n",
    "4. Fill in your HF_TOKEN where it prompts you\n",
    "\n",
    "### And now back to business: time to work with Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb8b6c41-8259-4329-b1c4-a1f67d26d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama import app, generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db4a718a-d95d-4f61-9688-c9df21d88fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2adb620e18940eda336eae05a4eb89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ“</span> Initialized. <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">View run at </span><span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2; text-decoration: underline\">https://modal.com/apps/nickbwalley/main/ap-EE8OCGfd80CA1q28J6hKdg</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ“\u001b[0m Initialized. \u001b[38;5;249mView run at \u001b[0m\u001b[4;38;5;249mhttps://modal.com/apps/nickbwalley/main/ap-EE8OCGfd80CA1q28J6hKdg\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ff8867c5734c5c8dff5b6481d3da2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ“</span> Created objects.\n",
       "<span style=\"color: #808080; text-decoration-color: #808080\">â”œâ”€â”€ </span>ðŸ”¨ Created mount D:\\MyProjects\\A.I-Projects\\llm_engineering\\week8\\llama.py\n",
       "<span style=\"color: #808080; text-decoration-color: #808080\">â”œâ”€â”€ </span>ðŸ”¨ Created mount PythonPackage:hello\n",
       "<span style=\"color: #808080; text-decoration-color: #808080\">â””â”€â”€ </span>ðŸ”¨ Created function generate.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ“\u001b[0m Created objects.\n",
       "\u001b[38;5;244mâ”œâ”€â”€ \u001b[0mðŸ”¨ Created mount D:\\MyProjects\\A.I-Projects\\llm_engineering\\week8\\llama.py\n",
       "\u001b[38;5;244mâ”œâ”€â”€ \u001b[0mðŸ”¨ Created mount PythonPackage:hello\n",
       "\u001b[38;5;244mâ””â”€â”€ \u001b[0mðŸ”¨ Created function generate.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125cf4f50ae8469692922fefd484b747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\n",
       "</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\n",
       "\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u001b[1ADownloading shards:   0%|          | 0/4 [00:00&lt;?, ?it/s]</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[1ADownloading shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\n",
       "</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\n",
       "\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u001b[1ADownloading shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [07:58&lt;23:54, 478.04s/it]</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[1ADownloading shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [07:58<23:54, 478.04s/it]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\n",
       "</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\n",
       "\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u001b[1ADownloading shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [15:58&lt;15:59, 479.55s/it]</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[1ADownloading shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [15:58<15:59, 479.55s/it]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\n",
       "</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\n",
       "\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u001b[1ADownloading shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [23:50&lt;07:56, 476.26s/it]</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[1ADownloading shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [23:50<07:56, 476.26s/it]\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\n",
       "</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\n",
       "\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u001b[1ADownloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [25:43&lt;00:00, 332.58s/it]Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [25:43&lt;00:00, 385.83s/it]\n",
       "</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[1ADownloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [25:43<00:00, 332.58s/it]Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [25:43<00:00, 385.83s/it]\n",
       "\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\n",
       "</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\n",
       "\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u001b[1ALoading checkpoint shards:   0%|          | 0/4 [00:00&lt;?, ?it/s]\n",
       "</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[1ALoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
       "\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u001b[1ALoading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:06&lt;00:20,  6.89s/it]\n",
       "</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[1ALoading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:06<00:20,  6.89s/it]\n",
       "\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u001b[1ALoading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:13&lt;00:13,  6.96s/it]\n",
       "</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[1ALoading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:13<00:13,  6.96s/it]\n",
       "\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u001b[1ALoading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:20&lt;00:06,  6.81s/it]\n",
       "</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[1ALoading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:20<00:06,  6.81s/it]\n",
       "\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u001b[1ALoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:22&lt;00:00,  4.82s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:22&lt;00:00,  5.57s/it]\n",
       "</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[1ALoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:22<00:00,  4.82s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:22<00:00,  5.57s/it]\n",
       "\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
       "</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[31mSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
       "\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Stopping app - local entrypoint completed.\n",
       "</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[33mStopping app - local entrypoint completed.\n",
       "\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Thread-5 (thread_inner)] 2025-02-26T12:56:55+0300 Loop attempt for _run_app.<locals>.heartbeat failed\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nickb\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\_utils\\async_utils.py\", line 195, in loop_coro\n",
      "    await asyncio.wait_for(async_f(), timeout=timeout)\n",
      "  File \"C:\\Users\\nickb\\anaconda3\\envs\\llms\\Lib\\asyncio\\tasks.py\", line 489, in wait_for\n",
      "    return fut.result()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nickb\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\runner.py\", line 53, in _heartbeat\n",
      "    await retry_transient_errors(client.stub.AppHeartbeat, request, attempt_timeout=HEARTBEAT_TIMEOUT)\n",
      "  File \"C:\\Users\\nickb\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\_utils\\grpc_utils.py\", line 184, in retry_transient_errors\n",
      "    raise exc\n",
      "  File \"C:\\Users\\nickb\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\_utils\\grpc_utils.py\", line 178, in retry_transient_errors\n",
      "    return await fn(*args, metadata=metadata, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nickb\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\client.py\", line 366, in __call__\n",
      "    return await self.client._call_unary(self._wrapped_method_name, req, timeout=timeout, metadata=metadata)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nickb\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\client.py\", line 308, in _call_unary\n",
      "    return await self._call_safely(coro, grpclib_method.name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nickb\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\client.py\", line 267, in _call_safely\n",
      "    return await request_task\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nickb\\anaconda3\\envs\\llms\\Lib\\site-packages\\grpclib\\client.py\", line 904, in __call__\n",
      "    reply = await stream.recv_message()\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nickb\\anaconda3\\envs\\llms\\Lib\\site-packages\\grpclib\\client.py\", line 425, in recv_message\n",
      "    await self.recv_initial_metadata()\n",
      "  File \"C:\\Users\\nickb\\anaconda3\\envs\\llms\\Lib\\site-packages\\grpclib\\client.py\", line 393, in recv_initial_metadata\n",
      "    self._raise_for_grpc_status(status, message, details)\n",
      "  File \"C:\\Users\\nickb\\anaconda3\\envs\\llms\\Lib\\site-packages\\grpclib\\client.py\", line 345, in _raise_for_grpc_status\n",
      "    raise GRPCError(status, message, details)\n",
      "grpclib.exceptions.GRPCError: (<Status.FAILED_PRECONDITION: 9>, 'App state is APP_STATE_STOPPED', None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ“</span> App completed. <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">View run at </span><span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2; text-decoration: underline\">https://modal.com/apps/nickbwalley/main/ap-EE8OCGfd80CA1q28J6hKdg</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ“\u001b[0m App completed. \u001b[38;5;249mView run at \u001b[0m\u001b[4;38;5;249mhttps://modal.com/apps/nickbwalley/main/ap-EE8OCGfd80CA1q28J6hKdg\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|>Life is a mystery, everyone must stand alone, I hear you call my name,'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with modal.enable_output():\n",
    "    with app.run():\n",
    "        result=generate.remote(\"Life is a mystery, everyone must stand alone, I hear\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a9a6844-29ec-4264-8e72-362d976b3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modal\n",
    "from pricer_ephemeral import app, price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50e6cf99-8959-4ae3-ba02-e325cb7fff94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105bc31fca704aae82bee4761f3b8e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ“</span> Initialized. <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">View run at </span><span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2; text-decoration: underline\">https://modal.com/apps/nickbwalley/main/ap-SOPTefffmekQPB6ZZ657qI</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ“\u001b[0m Initialized. \u001b[38;5;249mView run at \u001b[0m\u001b[4;38;5;249mhttps://modal.com/apps/nickbwalley/main/ap-SOPTefffmekQPB6ZZ657qI\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a991e2a6259c4c7a8a6260131bc80424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Stopping app - uncaught exception raised locally: NotFoundError(\"Could not find secret: 'huggingface-secret'. You can create it here: https://modal.com/secrets/nickbwalley/main/create?secret_name=huggingface-secret\").\n",
       "</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[33mStopping app - uncaught exception raised locally: NotFoundError(\"Could not find secret: 'huggingface-secret'. You can create it here: https://modal.com/secrets/nickbwalley/main/create?secret_name=huggingface-secret\").\n",
       "\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NotFoundError",
     "evalue": "Could not find secret: 'huggingface-secret'. You can create it here: https://modal.com/secrets/nickbwalley/main/create?secret_name=huggingface-secret",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m modal\u001b[38;5;241m.\u001b[39menable_output():\n\u001b[1;32m----> 2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQuadcast HyperX condenser mic, connects via usb-c to your computer for crystal clear audio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\synchronicity\\synchronizer.py:592\u001b[0m, in \u001b[0;36mSynchronizer._wrap_proxy_method.<locals>.proxy_method\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    590\u001b[0m instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[synchronizer_self\u001b[38;5;241m.\u001b[39m_original_attr]\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UserCodeException \u001b[38;5;28;01mas\u001b[39;00m uc_exc:\n\u001b[0;32m    594\u001b[0m     uc_exc\u001b[38;5;241m.\u001b[39mexc\u001b[38;5;241m.\u001b[39m__suppress_context__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\synchronicity\\combined_types.py:29\u001b[0m, in \u001b[0;36mFunctionWithAio.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UserCodeException \u001b[38;5;28;01mas\u001b[39;00m uc_exc:\n\u001b[0;32m     28\u001b[0m     uc_exc\u001b[38;5;241m.\u001b[39mexc\u001b[38;5;241m.\u001b[39m__suppress_context__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m uc_exc\u001b[38;5;241m.\u001b[39mexc\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\contextlib.py:210\u001b[0m, in \u001b[0;36m_AsyncGeneratorContextManager.__aenter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m anext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\app.py:379\u001b[0m, in \u001b[0;36m_App.run\u001b[1;34m(self, client, show_progress, detach, interactive, environment_name)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m show_progress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    377\u001b[0m     deprecation_warning((\u001b[38;5;241m2024\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m20\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`show_progress=False` is deprecated (and has no effect)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 379\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m _run_app(\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28mself\u001b[39m, client\u001b[38;5;241m=\u001b[39mclient, detach\u001b[38;5;241m=\u001b[39mdetach, interactive\u001b[38;5;241m=\u001b[39minteractive, environment_name\u001b[38;5;241m=\u001b[39menvironment_name\n\u001b[0;32m    381\u001b[0m ):\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\contextlib.py:210\u001b[0m, in \u001b[0;36m_AsyncGeneratorContextManager.__aenter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m anext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\runner.py:341\u001b[0m, in \u001b[0;36m_run_app\u001b[1;34m(app, client, detach, environment_name, interactive)\u001b[0m\n\u001b[0;32m    335\u001b[0m     logs_loop \u001b[38;5;241m=\u001b[39m tc\u001b[38;5;241m.\u001b[39mcreate_task(\n\u001b[0;32m    336\u001b[0m         get_app_logs_loop(client, output_mgr, app_id\u001b[38;5;241m=\u001b[39mrunning_app\u001b[38;5;241m.\u001b[39mapp_id, app_logs_url\u001b[38;5;241m=\u001b[39mrunning_app\u001b[38;5;241m.\u001b[39mapp_logs_url)\n\u001b[0;32m    337\u001b[0m     )\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;66;03m# Create all members\u001b[39;00m\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m _create_all_objects(client, running_app, app\u001b[38;5;241m.\u001b[39m_functions, app\u001b[38;5;241m.\u001b[39m_classes, environment_name)\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;66;03m# Publish the app\u001b[39;00m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m _publish_app(client, running_app, app_state, app\u001b[38;5;241m.\u001b[39m_functions, app\u001b[38;5;241m.\u001b[39m_classes)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\runner.py:174\u001b[0m, in \u001b[0;36m_create_all_objects\u001b[1;34m(client, running_app, functions, classes, environment_name)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    172\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected object \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;241m.\u001b[39mobject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m TaskContext\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m(_load(tag, obj) \u001b[38;5;28;01mfor\u001b[39;00m tag, obj \u001b[38;5;129;01min\u001b[39;00m indexed_objects\u001b[38;5;241m.\u001b[39mitems()))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\_utils\\async_utils.py:247\u001b[0m, in \u001b[0;36mTaskContext.gather\u001b[1;34m(*coros)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for a sequence of coroutines to finish, concurrently.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03mThis is similar to `asyncio.gather()`, but it uses TaskContext to cancel all remaining tasks\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m TaskContext() \u001b[38;5;28;01mas\u001b[39;00m tc:\n\u001b[1;32m--> 247\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m(tc\u001b[38;5;241m.\u001b[39mcreate_task(coro) \u001b[38;5;28;01mfor\u001b[39;00m coro \u001b[38;5;129;01min\u001b[39;00m coros))\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\runner.py:166\u001b[0m, in \u001b[0;36m_create_all_objects.<locals>._load\u001b[1;34m(tag, obj)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load\u001b[39m(tag, obj):\n\u001b[0;32m    165\u001b[0m     existing_object_id \u001b[38;5;241m=\u001b[39m tag_to_object_id\u001b[38;5;241m.\u001b[39mget(tag)\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m resolver\u001b[38;5;241m.\u001b[39mload(obj, existing_object_id)\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _Function\u001b[38;5;241m.\u001b[39m_is_id_type(obj\u001b[38;5;241m.\u001b[39mobject_id):\n\u001b[0;32m    168\u001b[0m         running_app\u001b[38;5;241m.\u001b[39mfunction_ids[tag] \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mobject_id\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\_resolver.py:157\u001b[0m, in \u001b[0;36mResolver.load\u001b[1;34m(self, obj, existing_object_id)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deduplication_cache[deduplication_key] \u001b[38;5;241m=\u001b[39m cached_future\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# TODO(elias): print original exception/trace rather than the Resolver-internal trace\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m cached_future\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\_resolver.py:124\u001b[0m, in \u001b[0;36mResolver.load.<locals>.loader\u001b[1;34m()\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mloader\u001b[39m():\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# Wait for all its dependencies\u001b[39;00m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m# TODO(erikbern): do we need existing_object_id for those?\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m TaskContext\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload(dep) \u001b[38;5;28;01mfor\u001b[39;00m dep \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mdeps()])\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m# Load the object itself\u001b[39;00m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_load:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\_utils\\async_utils.py:247\u001b[0m, in \u001b[0;36mTaskContext.gather\u001b[1;34m(*coros)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for a sequence of coroutines to finish, concurrently.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03mThis is similar to `asyncio.gather()`, but it uses TaskContext to cancel all remaining tasks\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m TaskContext() \u001b[38;5;28;01mas\u001b[39;00m tc:\n\u001b[1;32m--> 247\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m(tc\u001b[38;5;241m.\u001b[39mcreate_task(coro) \u001b[38;5;28;01mfor\u001b[39;00m coro \u001b[38;5;129;01min\u001b[39;00m coros))\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\_resolver.py:157\u001b[0m, in \u001b[0;36mResolver.load\u001b[1;34m(self, obj, existing_object_id)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deduplication_cache[deduplication_key] \u001b[38;5;241m=\u001b[39m cached_future\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# TODO(elias): print original exception/trace rather than the Resolver-internal trace\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m cached_future\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\_resolver.py:130\u001b[0m, in \u001b[0;36mResolver.load.<locals>.loader\u001b[1;34m()\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no loader function\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_load(obj, \u001b[38;5;28mself\u001b[39m, existing_object_id)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GRPCError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m Status\u001b[38;5;241m.\u001b[39mNOT_FOUND:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\secret.py:200\u001b[0m, in \u001b[0;36m_Secret.from_name.<locals>._load\u001b[1;34m(self, resolver, existing_object_id)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GRPCError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m Status\u001b[38;5;241m.\u001b[39mNOT_FOUND:\n\u001b[1;32m--> 200\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotFoundError(exc\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Could not find secret: 'huggingface-secret'. You can create it here: https://modal.com/secrets/nickbwalley/main/create?secret_name=huggingface-secret"
     ]
    }
   ],
   "source": [
    "with modal.enable_output():\n",
    "    with app.run():\n",
    "        result=price.remote(\"Quadcast HyperX condenser mic, connects via usb-c to your computer for crystal clear audio\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8747f-8452-4077-8af6-27e03888508a",
   "metadata": {},
   "source": [
    "## Transitioning From Ephemeral Apps to Deployed Apps\n",
    "\n",
    "From a command line, `modal deploy xxx` will deploy your code as a Deployed App\n",
    "\n",
    "This is how you could package your AI service behind an API to be used in a Production System.\n",
    "\n",
    "You can also build REST endpoints easily, although we won't cover that as we'll be calling direct from Python.\n",
    "\n",
    "## Important note for Windows people:\n",
    "\n",
    "On the next line, I call `modal deploy` from within Jupyter lab; I've heard that on some versions of Windows this gives a strange unicode error because modal prints emojis to the output which can't be displayed. If that happens to you, simply use an Anaconda Prompt window or a Powershell instead, with your environment activated, and type `modal deploy pricer_service` there. Follow the same approach the next time we do `!modal deploy` too.\n",
    "\n",
    "As an alternative, a few students have mentioned you can run this code within Jupyter Lab if you want to run it from here:\n",
    "```\n",
    "# Check the default encoding\n",
    "print(locale.getpreferredencoding())  # Should print 'UTF-8'\n",
    "\n",
    "# Ensure UTF-8 encoding\n",
    "os.environ['PYTHONIOENCODING'] = 'utf-8'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f90d857-2f12-4521-bb90-28efd917f7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Creating objects...\n",
      "| Creating objects...\n",
      "- Creating objects...\n",
      "| Creating objects...\n",
      "/ Creating objects...\n",
      "`-- - Creating mount \n",
      "    D:\\MyProjects\\A.I-Projects\\llm_engineering\\week8\\pricer_service.py: \n",
      "    Uploaded 0/1 files\n",
      "\\ Creating objects...\n",
      "`-- \\ Creating mount \n",
      "    D:\\MyProjects\\A.I-Projects\\llm_engineering\\week8\\pricer_service.py: \n",
      "    Uploaded 0/1 files\n",
      "/ Creating objects...\n",
      "`-- / Creating mount \n",
      "    D:\\MyProjects\\A.I-Projects\\llm_engineering\\week8\\pricer_service.py: \n",
      "    Uploaded 0/1 files\n",
      "\\ Creating objects...\n",
      "`-- \\ Creating mount \n",
      "    D:\\MyProjects\\A.I-Projects\\llm_engineering\\week8\\pricer_service.py: \n",
      "    Finalizing index of 1 files\n",
      "/ Creating objects...\n",
      "`-- / Creating mount \n",
      "    D:\\MyProjects\\A.I-Projects\\llm_engineering\\week8\\pricer_service.py: \n",
      "    Finalizing index of 1 files\n",
      "\\ Creating objects...\n",
      "`-- \\ Creating mount \n",
      "    D:\\MyProjects\\A.I-Projects\\llm_engineering\\week8\\pricer_service.py: \n",
      "    Finalizing index of 1 files\n",
      "/ Creating objects...\n",
      "+-- \n",
      "/ Creating objects...\n",
      "+-- \n",
      "/ Creating objects...\n",
      "+-- \n",
      "/ Creating objects...\n",
      "+-- \n",
      "/ Creating objects...\n",
      "+-- \n",
      "\\ Creating objects...\n",
      "+-- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+- Error ---------------------------------------------------------------------+\n",
      "| 'charmap' codec can't encode character '\\U0001f528' in position 0:          |\n",
      "| character maps to <undefined>                                               |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!modal deploy pricer_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dec70ff-1986-4405-8624-9bbbe0ce1f4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "App not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pricer \u001b[38;5;241m=\u001b[39m \u001b[43mmodal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpricer-service\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\synchronicity\\combined_types.py:29\u001b[0m, in \u001b[0;36mFunctionWithAio.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UserCodeException \u001b[38;5;28;01mas\u001b[39;00m uc_exc:\n\u001b[0;32m     28\u001b[0m     uc_exc\u001b[38;5;241m.\u001b[39mexc\u001b[38;5;241m.\u001b[39m__suppress_context__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m uc_exc\u001b[38;5;241m.\u001b[39mexc\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\functions.py:1110\u001b[0m, in \u001b[0;36m_Function.lookup\u001b[1;34m(app_name, name, namespace, client, environment_name)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _Client\u001b[38;5;241m.\u001b[39mfrom_env()\n\u001b[0;32m   1109\u001b[0m resolver \u001b[38;5;241m=\u001b[39m Resolver(client\u001b[38;5;241m=\u001b[39mclient)\n\u001b[1;32m-> 1110\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m resolver\u001b[38;5;241m.\u001b[39mload(obj)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\_resolver.py:157\u001b[0m, in \u001b[0;36mResolver.load\u001b[1;34m(self, obj, existing_object_id)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deduplication_cache[deduplication_key] \u001b[38;5;241m=\u001b[39m cached_future\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# TODO(elias): print original exception/trace rather than the Resolver-internal trace\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m cached_future\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\_resolver.py:130\u001b[0m, in \u001b[0;36mResolver.load.<locals>.loader\u001b[1;34m()\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no loader function\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_load(obj, \u001b[38;5;28mself\u001b[39m, existing_object_id)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GRPCError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m Status\u001b[38;5;241m.\u001b[39mNOT_FOUND:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\modal\\functions.py:1077\u001b[0m, in \u001b[0;36m_Function.from_name.<locals>._load_remote\u001b[1;34m(self, resolver, existing_object_id)\u001b[0m\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GRPCError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1076\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m Status\u001b[38;5;241m.\u001b[39mNOT_FOUND:\n\u001b[1;32m-> 1077\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotFoundError(exc\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1079\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: App not found"
     ]
    }
   ],
   "source": [
    "pricer = modal.Function.lookup(\"pricer-service\", \"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17776139-0d9e-4ad0-bcd0-82d3a92ca61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pricer.remote(\"Quadcast HyperX condenser mic, connects via usb-c to your computer for crystal clear audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56d1e55-2a03-4ce2-bb47-2ab6b9175a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also run \"modal deploy pricer_service2\" at the command line in an activated environment\n",
    "!modal deploy pricer_service2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e19daeb-1281-484b-9d2f-95cc6fed2622",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pricer = modal.Cls.lookup(\"pricer-service\", \"Pricer\")\n",
    "pricer = Pricer()\n",
    "reply = pricer.price.remote(\"Quadcast HyperX condenser mic, connects via usb-c to your computer for crystal clear audio\")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1b1451-6249-4462-bf2d-5937c059926c",
   "metadata": {},
   "source": [
    "# Optional: Keeping Modal warm\n",
    "\n",
    "## A way to improve the speed of the Modal pricer service\n",
    "\n",
    "A student mentioned to me that he was concerned by how slow Modal seems to be. The reason is that Modal puts our service to sleep if we don't use it, and then it takes 2.5 minutes to spin back up.\n",
    "\n",
    "I've added a utility called `keep_warm.py` that will keep our Modal warm by pinging it every 30 seconds.\n",
    "\n",
    "To use the utliity, bring up a new Terminal (Mac) or Anaconda prompt (Windows), ensure the environment is activated with `conda activate llms`\n",
    "\n",
    "Then run: `python keep_warm.py` from within the week8 drectory.\n",
    "\n",
    "Remember to press ctrl+C or exit the window when you no longer need Modal running.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3754cfdd-ae28-47c8-91f2-6e060e2c91b3",
   "metadata": {},
   "source": [
    "## And now introducing our Agent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9aedca-6a7b-4d30-9f64-59d76f76fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.specialist_agent import SpecialistAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5843e5-e958-4a65-8326-8f5b4686de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SpecialistAgent()\n",
    "agent.price(\"iPad Pro 2nd generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a3181b-1310-4102-8d7d-52caf4c00538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
